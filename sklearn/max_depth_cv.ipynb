{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máxima profundidad de árbol de decisión mediante validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo del error de un árbol sin limitar la profundidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.78"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_no_limit = DecisionTreeRegressor(random_state=42)\n",
    "mae_no_limit = -cross_val_score(tree_no_limit, X_train, y_train,\n",
    "                            scoring = \"neg_mean_absolute_error\",\n",
    "                            cv = 10).mean().round(2)\n",
    "mae_no_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso un diccionario de modelos con diferentes profundidades máximas y otro con los errores medios absolutos obtenidos en la validación cruzada.\n",
    "\n",
    "Los inicializo con el modelo sin limitación de profundidad y la clave None (la misma que usa por defecto el parámetro `max_depth` de `DecisionTreeRegressor` para no limitar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth = {None: tree_no_limit}\n",
    "maes_depth = {None: mae_no_limit}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    tree_depth[i] = DecisionTreeRegressor(random_state=42, max_depth=i)\n",
    "    maes_depth[i] = -cross_val_score(tree_depth[i], X_train, y_train,\n",
    "                              scoring = \"neg_mean_absolute_error\").mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad None - MAE: 65.78\n",
      "Profundidad 1 - MAE: 56.0\n",
      "Profundidad 2 - MAE: 50.0\n",
      "Profundidad 3 - MAE: 52.0\n",
      "Profundidad 4 - MAE: 53.0\n",
      "Profundidad 5 - MAE: 54.0\n",
      "Profundidad 6 - MAE: 56.0\n",
      "Profundidad 7 - MAE: 59.0\n",
      "Profundidad 8 - MAE: 60.0\n",
      "Profundidad 9 - MAE: 61.0\n",
      "La mejor profundidad es 2 con un MAE de 50.0\n"
     ]
    }
   ],
   "source": [
    "for depth, mae in maes_depth.items():\n",
    "    print(f\"Profundidad {depth} - MAE: {mae}\")\n",
    "\n",
    "depth_min_mae = min(maes_depth, key=maes_depth.get)\n",
    "print(f\"La mejor profundidad es {depth_min_mae} con un MAE de {maes_depth[depth_min_mae]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que entre los valores arbitrariamente elegidos de profundidad [1-10] encontramos un *mínimo de la función de coste en profundidad 2*, incrementándose consistentemente en los siguientes y siendo inferior también que un árbol sin límite. Parece por tanto razonable asumir que no haya otros mínimos en profundidades superiores.\n",
    "\n",
    "Fijaremos por tanto el **hiperparámetro** de profundidad en 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definidos los hiperparámetros, entrenamos el modelo con el conjunto de entrenamiento completo y **evaluamos su rendimiento con el conjunto de test, que no se ha usado en ningún entrenamiento y por tanto no ha sesgado la elección de hiperparámetros**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MAE(test): 49.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model = tree_depth[depth_min_mae].fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "print(\" MAE(test):\", mae_test.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternativa: elección del hiperparámetro utilizando GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(max_depth=2, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "params = {\n",
    "    'max_depth': list(range(1, 10)),\n",
    "}\n",
    "grid_search_cv = GridSearchCV(tree, params, cv=10,\n",
    "                              scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "grid_search_cv.fit(dataset.data, dataset.target)\n",
    "print(grid_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TODO: ## Regresión polinómica -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
